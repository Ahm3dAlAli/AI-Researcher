\section{Introduction}

Learning with [data type], such as [examples], requires effective representation of their [specific structures]. Recently, there has been a surge of interest in [method/field/approach] for [task/goal] (cite relevant works). [Method/field] broadly follows a [description of approach], where each [entity/type] aggregates [data type] of its [local context] to compute its new [output type] (cite relevant works). After [number] iterations of aggregation, a [entity/type] is represented by its transformed [output type], which captures the [descriptive property] within the [entity/type]'s [context]. The representation of [larger entity] can then be obtained through [method] (cite relevant works).

Many [method variants] with different [features] and [top-level operations] have been proposed (cite several relevant works). Empirically, these [method type] have achieved [description of performance] in many tasks such as [task 1], [task 2], and [task 3]. However, the design of new [method type] is mostly based on empirical intuition, heuristics, and experimental trial-and-error. There is little theoretical understanding of the properties and limitations of [method type], and formal analysis of [their capacities] is limited.

Here, we present a theoretical framework for analyzing the [property/characteristic] of [method type]. We formally characterize how expressive different [method variants] are in [purpose of analysis]. Our framework is inspired by [previous work/technique], a powerful [test/analysis] known to [describe capability]. Similar to [method type], [previous work] iteratively updates a given [entity/type]'s [data type] by aggregating [data type] of its [local context]. What makes [previous work] so powerful is its [describe key feature]. Our key insight is that a [method type] can have as large [property] as [previous work] if the [method type]'s [operation] is [descriptive quality].

To mathematically formalize the above insight, our framework first represents the set of [data type] of a given [entity/type]'s [local context] as a [set type]. Then, the [aggregating operation] in [method type] can be thought of as an [operation type] over the [set type]. Hence, to have strong [property], a [method type] must be able to [action] different [set types] into different representations. We rigorously study several variants of [operation type] and theoretically characterize their [descriptive property], i.e., how well different [operation types] can distinguish different [set types]. The more discriminative the [operation type] is, the more powerful the [property] of the underlying [method type].

Our main results are summarized as follows:

- 1) We show that [method type] are at most as powerful as [benchmark comparison].
- 2) We establish conditions on the [feature] and [top-level operation] functions under which the resulting [method type] is as powerful as [benchmark comparison].
- 3) We identify [specific cases] that cannot be distinguished by [previous method variants], and we precisely characterize the kinds of [cases] such [method type] can capture.
- 4) We develop a new [method/architecture], and show that its [property] is equal to the power of [benchmark comparison].

We validate our theory via experiments on [relevant datasets], where the [describe property] of [method type] is crucial to capture [specific structures]. In particular, we compare the performance of [method type] with various [operation types]. Our results confirm that the most powerful [method type] by our theory, i.e., [specific method type], also empirically has high [property] as it almost perfectly fits the [training context], whereas the less powerful [method variants] often severely underfit the [training context]. In addition, the [specific property] [method type] outperform the others by [criteria] and achieve [level of performance] on many [benchmark tasks].